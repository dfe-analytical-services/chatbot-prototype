{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import pinecone\n",
    "import openai\n",
    "from time import sleep\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#document = fitz.open('C:/Users/JSHARRATT/Documents/gpt4-langchain-dfe/backend/docs/sample.pdf')\n",
    "#pattern = r'(?<=\\s)\\\\.*?\\\\(?=\\s)'\n",
    "\n",
    "#whole_text = []\n",
    "#for index, page in enumerate(document):\n",
    " #   if (index>90 or index < 6):\n",
    " #       continue\n",
    " #   text = page.get_text()\n",
    " #   whole_text.append(text)\n",
    "\n",
    "#decoded_text = []\n",
    "#for ind, page in enumerate(whole_text):\n",
    "#    page = page.replace(\"\\n\", ' ')\n",
    "#    page = page.replace(\"\\\\xc2\\\\xa3\", \"Â£\")\n",
    "#    page = page.replace(\"\\\\xe2\\\\x80\\\\x93\", \"-\")\n",
    "###    #decoded_text['id'].append(str(ind))\n",
    "###    #decoded_text['text'].append(page)\n",
    "#    decoded_text.append(page)\n",
    "\n",
    "url = \"https://explore-education-statistics.service.gov.uk/find-statistics/pupil-attendance-in-schools\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    text = \" \".join(t.strip() for t in soup.stripped_strings)\n",
    "    decoded_text = text.replace('\\xa0', ' ')\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #chunk_size=400,\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inserted_string = \" Overall absence rate 7.0 %% during week commencing 20 March 2023 Authorised absence rate was 4.7 %% during week commencing 20 March 2023 Unauthorised absence rate was 2.3 %% during week commencing 20 March 2023 Overall absence rate was 7.5 %% academic year to date Authorised absence rate was 5.2 %% academic year to date Unauthorised absence rate was 2.3 %% academic year to date Persistent absence rate was 22.4 %% academic year to date \"\n",
    "\n",
    "n = decoded_text.index(\"Headline facts and figures - 2023\") + len(\"Headline facts and figures - 2023\")\n",
    "decoded_text = decoded_text[:n] + inserted_string + decoded_text[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "\n",
    "\n",
    "texts = text_splitter.split_text(decoded_text)\n",
    "chunks.extend([{\n",
    "        'id': str(uuid4()),\n",
    "        'text': texts[i],\n",
    "        'chunk': i\n",
    "    } for i in range(len(texts))])\n",
    "\n",
    "\n",
    "openai.api_key = \"\" \n",
    "\n",
    "embed_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55223229b0a74f11bc892c019bbcb683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings upserted\n"
     ]
    }
   ],
   "source": [
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")\n",
    "\n",
    "\n",
    "index_name = 'edtech-gpt'\n",
    "\n",
    "# initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key='',  # app.pinecone.io (console)\n",
    "    environment=\"northamerica-northeast1-gcp\"  # next to API key in console\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk']\n",
    "    } for x in meta_batch]\n",
    "    \n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)\n",
    "    print(\"Embeddings upserted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
